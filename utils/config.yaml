main:
  input_dir: data/sample/original
  annot_clean: 'off'
  yolo_crop: 'on'
  yolo_model: yolov4
  classify_model: mobilenet_v2
  saved_model: saved_model/
  metrics_dir: metrics/
annotation_cleaner:
  main:
    input_dir: data/sample/original
    output_dir: data/sample/generation
    categories:
    - repair
    - replace
    metadata_name: padding_info.json
    keep_metadata: false
  image_padding:
    input_dir: data/sample/annotation_cleaner/only_annotation_image
    output_dir: data/sample/annotation_cleaner/only_annotation_image_padded
    target_size: 1024
  annotation_clean:
    input_dir: data/sample/annotation_cleaner/only_annotation_image_padded
    output_dir: sample/annotation_cleaner/generated_image_padded
    test_mode: 'off'
    test_limit: 6
    model: gemini-2.5-flash-image-preview
    api_key: ${GEMINI_API_KEY}
    prompt: 'In this image, do not alter or modify the cracked or damaged area of
      the glass in any way. Preserve this area exactly as it appears. Remove only
      artificial annotations (lines, circles, arrows, or handwritten text of any color)
      and any extraneous objects near the damaged area (such as fingers, hands, or
      other human body parts). Ensure the surface of the window, including reflections
      and lighting, remains natural and realistic after inpainting. The output image
      must have exactly the same width and height as the input image, with no resizing,
      scaling, or cropping.

      '
    temperature: 0.0
    max_retries: 3
    timeout: 60
  restore_crop:
    input_dir: data/sample/annotation_cleaner/generated_image_padded
    output_dir: data/sample/annotation_cleaner/generated_image
    metadata_root: sample/annotation_cleaner/only_annotation_image_padded
  evaluate:
    orig_dir: data/sample/annotation_cleaner/only_annotation_image
    gen_dir: data/sample/annotation_cleaner/generated_image
    metric_dir: ./metrics/annotation_cleaner
    metrics:
    - ssim
    - edge_iou
    - l1
    yolo_model: ./saved_model/yolo_cropper/yolov8s.pt
    imgsz: 416
yolo_cropper:
  main:
    model_name: yolov4
    input_dir: /home/stu_hwang_kh/Research/data/sample/original
    output_dir: /home/stu_hwang_kh/Research/data/sample/original_crop/yolov4
  dataset:
    results_dir: outputs/json_results
    train_data_dir: data/yolo_cropper
    saved_model_dir: saved_model/yolo_cropper
    checkpoint_dir: checkpoints/yolo_cropper
    metrics_dir: metrics/yolo_cropper
    detect_output_dir: runs/detect
    train_output_dir: runs/train
  train:
    batch_size: 16
    epochs: 400
    imgsz: 416
    device: 0
    save_crop: false
    save_txt: true
    save_conf: true
  darknet:
    model_name: yolov4
    build_mode: cpu
    darknet_dir: third_party/darknet
    darknet_data_dir: third_party/darknet/data
    modes:
      cpu:
        GPU: 0
        CUDNN: 0
        CUDNN_HALF: 0
        OPENCV: 1
        MAKE_JOBS: 4
      gpu:
        GPU: 1
        CUDNN: 1
        CUDNN_HALF: 1
        OPENCV: 1
        MAKE_JOBS: 8
    cfg_overrides:
      batch: 64
      subdivisions: 16
      width: 416
      height: 416
      channels: 3
      momentum: 0.949
      decay: 0.0005
      learning_rate: 0.001
      burn_in: 1000
      max_batches: 6000
      policy: steps
      steps: 4800,5400
      scales: .1,.1
      mosaic: 0
      saturation: 1.5
      exposure: 1.5
      hue: 0.1
      classes: 2
      iou_loss: ciou
      nms_kind: greedynms
      beta_nms: 0.6
      iou_thresh: 0.213
      cls_normalizer: 1.0
      iou_normalizer: 0.07
  yolov5:
    yolov5_dir: third_party/yolov5
    data_yaml: data/yolo_cropper/yolov5/data.yaml
  yolov8:
    data_yaml: data/yolo_cropper/yolov8/data.yaml
data_augmentor:
  data:
    input_dir: /home/stu_hwang_kh/Research/data/sample/original_crop/yolov4
    output_dir: /home/stu_hwang_kh/Research/data/sample/original_crop/yolov4
  split:
    train_ratio: 0.8
    valid_ratio: 0.1
    test_ratio: 0.1
  augmentation:
    enable: true
    random_resized_crop:
      scale:
      - 0.9
      - 1.0
      ratio:
      - 0.95
      - 1.05
    random_hflip_p: 0.5
    random_rotate_deg: 10
    random_translate_ratio: 0.04
    brightness_range:
    - 0.9
    - 1.1
    contrast_range:
    - 0.9
    - 1.15
    saturation_range:
    - 0.9
    - 1.15
    hue_delta: 0.03
  dataset:
    input_dir: data/generation_crop/yolov8s
classifier:
  data:
    input_dir: /home/stu_hwang_kh/Research/data/sample/original_crop/yolov4
  train:
    model_name: mobilenet_v2
    batch_size: 32
    epochs: 80
    lr: 0.001
    weight_decay: 1.0e-05
    save_dir: ./saved_model/classifier
    metric_dir: ./metrics/classifier
    check_dir: ./checkpoints/classifier
  wandb:
    enabled: true
    project: Crop-for-Trust
    entity: kyeonghah-university-of-suwon
    run_name_pattern: '{model}_{input_dir}'
    notes: Crop-for-Trust

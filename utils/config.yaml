main:
  input_dir: data/sample/original
  annot_clean: 'off'
  yolo_crop: 'on'
  yolo_model: yolov5
  classify_model: resnet
  saved_model: saved_model/
  metrics_dir: metrics/
  demo: 'off'
weights:
  yolov2: https://github.com/kyeongha-git/Crop-for-Trust/releases/download/v1/yolov2.weights
  yolov4: https://github.com/kyeongha-git/Crop-for-Trust/releases/download/v1/yolov4.weights
  yolov5: https://github.com/kyeongha-git/Crop-for-Trust/releases/download/v1/yolov5.pt
  yolov8s: https://github.com/kyeongha-git/Crop-for-Trust/releases/download/v1/yolov8s.pt
  yolov8m: https://github.com/kyeongha-git/Crop-for-Trust/releases/download/v1/yolov8m.pt
  yolov8l: https://github.com/kyeongha-git/Crop-for-Trust/releases/download/v1/yolov8l.pt
  yolov8x: https://github.com/kyeongha-git/Crop-for-Trust/releases/download/v1/yolov8x.pt
sha256:
  yolov2: 25c06d72ab7be602128dec074b8b8dbf36c2aead41637352cde5821de2157ebf
  yolov4: 202e6cea417e12bc6d65f8db91a7ef8c334ae69cbf1044d4594bb2c265d759b3
  yolov5: 07e8ad9d67c42a4462ec4adf73ca40f4dc8730ab51b1c7f33b168474dba51f4c
  yolov8s: e9c6f26b7654639fca041faad31beca1a1c388ffc05e805581f9b03b798491ce
  yolov8m: 14de68f9120fc4c0cd9ab26e0f2f78cbf8b456a19e141f437f3b34e9203e9062
  yolov8l: ca2848fcd25580ec765a95cc2aa72e0445331d5fccef7c4b5939164a5176c333
  yolov8x: 79d058f5165fd663192d6885b10e88956fe4c36dcc2cd340a9033bed14bd065d
annotation_cleaner:
  main:
    input_dir: data/sample/original
    output_dir: data/sample/generation
    categories:
    - repair
    - replace
    metadata_name: padding_info.json
    keep_metadata: false
  image_padding:
    input_dir: data/sample/annotation_cleaner/only_annotation_image
    output_dir: data/sample/annotation_cleaner/only_annotation_image_padded
    target_size: 1024
  annotation_clean:
    input_dir: data/sample/annotation_cleaner/only_annotation_image_padded
    output_dir: sample/annotation_cleaner/generated_image_padded
    test_mode: 'off'
    test_limit: 6
    model: gemini-2.5-flash-image-preview
    api_key: ${GEMINI_API_KEY}
    prompt: 'In this image, do not alter or modify the cracked or damaged area of
      the glass in any way. Preserve this area exactly as it appears. Remove only
      artificial annotations (lines, circles, arrows, or handwritten text of any color)
      and any extraneous objects near the damaged area (such as fingers, hands, or
      other human body parts). Ensure the surface of the window, including reflections
      and lighting, remains natural and realistic after inpainting. The output image
      must have exactly the same width and height as the input image, with no resizing,
      scaling, or cropping. '
    temperature: 0.0
    max_retries: 3
    timeout: 60
  restore_crop:
    input_dir: data/sample/annotation_cleaner/generated_image_padded
    output_dir: data/sample/annotation_cleaner/generated_image
    metadata_root: data/sample/annotation_cleaner/only_annotation_image_padded
  evaluate:
    orig_dir: data/sample/annotation_cleaner/only_annotation_image
    gen_dir: data/sample/annotation_cleaner/generated_image
    metric_dir: ./metrics/annotation_cleaner
    metrics:
    - ssim
    - edge_iou
    - l1
    yolo_model: ./saved_model/yolo_cropper/yolov8s.pt
    imgsz: 416
yolo_cropper:
  main:
    model_name: yolov2
    input_dir: /home/stu_hwang_kh/crop_for_trust/data/sample/original
    output_dir: /home/stu_hwang_kh/crop_for_trust/data/sample/original_crop/yolov2
  dataset:
    results_dir: outputs/json_results
    train_data_dir: data/yolo_cropper
    saved_model_dir: saved_model/yolo_cropper
    checkpoint_dir: checkpoints/yolo_cropper
    metrics_dir: metrics/yolo_cropper
    detect_output_dir: runs/detect
    train_output_dir: runs/train
  train:
    batch_size: 16
    epochs: 400
    imgsz: 416
    device: 0
    save_crop: false
    save_txt: true
    save_conf: true
  darknet:
    model_name: yolov4
    build_mode: cpu
    darknet_dir: third_party/darknet
    darknet_data_dir: third_party/darknet/data
    modes:
      cpu:
        GPU: 0
        CUDNN: 0
        CUDNN_HALF: 0
        OPENCV: 1
        MAKE_JOBS: 4
      gpu:
        GPU: 1
        CUDNN: 1
        CUDNN_HALF: 1
        OPENCV: 1
        MAKE_JOBS: 8
    cfg_overrides:
      batch: 64
      subdivisions: 16
      width: 416
      height: 416
      channels: 3
      momentum: 0.949
      decay: 0.0005
      learning_rate: 0.001
      burn_in: 1000
      max_batches: 6000
      policy: steps
      steps: 4800,5400
      scales: .1,.1
      mosaic: 0
      saturation: 1.5
      exposure: 1.5
      hue: 0.1
      classes: 2
      iou_loss: ciou
      nms_kind: greedynms
      beta_nms: 0.6
      iou_thresh: 0.213
      cls_normalizer: 1.0
      iou_normalizer: 0.07
  yolov5:
    yolov5_dir: third_party/yolov5
    data_yaml: data/yolo_cropper/yolov5/data.yaml
  yolov8:
    data_yaml: data/yolo_cropper/yolov8/data.yaml
data_augmentor:
  data:
    input_dir: /home/stu_hwang_kh/crop_for_trust/data/sample/original_crop/yolov2
    output_dir: null
  split:
    train_ratio: 0.8
    valid_ratio: 0.1
    test_ratio: 0.1
  augmentation:
    enable: true
    random_resized_crop:
      scale:
      - 0.9
      - 1.0
      ratio:
      - 0.95
      - 1.05
    random_hflip_p: 0.5
    random_rotate_deg: 10
    random_translate_ratio: 0.04
    brightness_range:
    - 0.9
    - 1.1
    contrast_range:
    - 0.9
    - 1.15
    saturation_range:
    - 0.9
    - 1.15
    hue_delta: 0.03
classifier:
  data:
    input_dir: /home/stu_hwang_kh/crop_for_trust/data/sample/original_crop/yolov2/dataset
  train:
    batch_size: 2
    epochs: 1
    lr: 0.001
    weight_decay: 1.0e-05
    save_dir: saved_model/classifier/sample/original_crop/yolov2
    metric_dir: metrics/classifier/sample/original_crop/yolov2
    check_dir: ./checkpoints/classifier
  wandb:
    enabled: false
    project: Crop-for-Trust
    entity: kyeonghah-university-of-suwon
    run_name_pattern: '{model}_{input_dir}'
    notes: Crop-for-Trust

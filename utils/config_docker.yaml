main:
  input_dir: data/sample/original
  annot_clean: 'off'
  yolo_crop: 'on'
  yolo_model: yolov8s
  classify_model: mobilenet_v2
  saved_model: saved_model/
  metrics_dir: metrics/
  demo: 'on'
annotation_cleaner:
  main:
    input_dir: /app/data/sample/original
    output_dir: /app/data/sample/generation
    categories:
    - repair
    - replace
    metadata_name: padding_info.json
    keep_metadata: false
  image_padding:
    input_dir: /app/data/sample/annotation_cleaner/only_annotation_image
    output_dir: /app/data/sample/annotation_cleaner/only_annotation_image_padded
    target_size: 1024
  annotation_clean:
    input_dir: /app/data/sample/annotation_cleaner/only_annotation_image_padded
    output_dir: /app/data/sample/annotation_cleaner/generated_image_padded
    test_mode: 'off'
    test_limit: 6
    model: gemini-2.5-flash-image-preview
    api_key: ${GEMINI_API_KEY}
    prompt: 'In this image, do not alter or modify the cracked or damaged area of
      the glass in any way. Preserve this area exactly as it appears. Remove only
      artificial annotations (lines, circles, arrows, or handwritten text of any color)
      and any extraneous objects near the damaged area (such as fingers, hands, or
      other human body parts). Ensure the surface of the window, including reflections
      and lighting, remains natural and realistic after inpainting. The output image
      must have exactly the same width and height as the input image, with no resizing,
      scaling, or cropping. '
    temperature: 0.0
    max_retries: 3
    timeout: 60
  restore_crop:
    input_dir: /app/data/sample/annotation_cleaner/generated_image_padded
    output_dir: /app/data/sample/annotation_cleaner/generated_image
    metadata_root: /app/data/sample/annotation_cleaner/only_annotation_image_padded
  evaluate:
    orig_dir: /app/data/sample/annotation_cleaner/only_annotation_image
    gen_dir: /app/data/sample/annotation_cleaner/generated_image
    metric_dir: ./metrics/annotation_cleaner
    metrics:
    - ssim
    - edge_iou
    - l1
    yolo_model: ./saved_model/yolo_cropper/yolov8s.pt
    imgsz: 416
yolo_cropper:
  main:
    model_name: yolov8s
    input_dir: /app/data/sample/original
    output_dir: /app/data/sample/original_crop/yolov8s
    mode: detect
  dataset:
    results_dir: outputs/json_results
    saved_model_dir: saved_model/yolo_cropper
    detect_output_dir: runs/detect
  inference:
    conf_thresh: 0.25
    iou_thresh: 0.45
    imgsz: 416
    device: cpu
    save_crop: true
    save_txt: false
data_augmentor:
  data:
    input_dir: /app/data/sample/original_crop/yolov8s
    output_dir: null
  split:
    train_ratio: 0.8
    valid_ratio: 0.1
    test_ratio: 0.1
  augmentation:
    enable: true
    random_resized_crop:
      scale:
      - 0.9
      - 1.0
      ratio:
      - 0.95
      - 1.05
    random_hflip_p: 0.5
    random_rotate_deg: 10
    random_translate_ratio: 0.04
    brightness_range:
    - 0.9
    - 1.1
    contrast_range:
    - 0.9
    - 1.15
    saturation_range:
    - 0.9
    - 1.15
    hue_delta: 0.03
classifier:
  data:
    input_dir: /app/data/sample/original_crop/yolov8s/dataset
  train:
    model_name: mobilenet_v2
    batch_size: 2
    epochs: 1
    lr: 0.001
    weight_decay: 1.0e-05
    save_dir: ./saved_model/classifier
    metric_dir: ./metrics/classifier
    check_dir: ./checkpoints/classifier
  wandb:
    enabled: false
    project: Crop-for-Trust
    entity: kyeonghah-university-of-suwon
    run_name_pattern: '{model}_{input_dir}'
    notes: Crop-for-Trust
